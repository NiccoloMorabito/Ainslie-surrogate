{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import random\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from src.data_loaders import get_wake_datasets\n",
    "from src.evaluation import evaluate_model\n",
    "import src.plotting as plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACTORS_FOLDER = \"discr_factors_x2_30_y-2_2_step0.125_TIstep0.01_CTstep0.01\"\n",
    "DATA_FOLDER = f\"../../data/{FACTORS_FOLDER}/\"\n",
    "\n",
    "INPUT_VAR_TO_TRAIN_REDUCTION_FACTOR = {\"ti\": 4, \"ct\": 4}\n",
    "train_reduc_factor_string = \"training_factors=\" + \"-\".join(\n",
    "    [f\"{k}{v}\" for k, v in INPUT_VAR_TO_TRAIN_REDUCTION_FACTOR.items()]\n",
    ")\n",
    "# INPUT_VAR_TO_TRAIN_RANGES = {'ti': [(0.15, 0.4)], 'ct': [(0.3, 0.7)]}\n",
    "# train_range_string = \"training_ranges=\" + '-'.join([f\"{var}{r[0]}-{r[1]}\" for var, ranges in INPUT_VAR_TO_TRAIN_RANGES.items() for r in ranges])\n",
    "CONSIDER_WS = False\n",
    "COORDS_AS_INPUT = True  # univariate setting\n",
    "\n",
    "MODEL_NAME = f\"univariate_XGB_{train_reduc_factor_string}\"\n",
    "if CONSIDER_WS:\n",
    "    MODEL_NAME += \"_consider_ws\"\n",
    "MODEL_DESCRIPTION = f\"{MODEL_NAME}_{FACTORS_FOLDER}\"\n",
    "print(MODEL_DESCRIPTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset, test_dataset = get_wake_datasets(\n",
    "    DATA_FOLDER,\n",
    "    consider_ws=CONSIDER_WS,\n",
    "    coords_as_input=COORDS_AS_INPUT,\n",
    "    # train_perc=0.6,\n",
    "    # validation_perc=0.2,\n",
    "    # test_perc=0.2\n",
    "    input_var_to_train_reduction_factor=INPUT_VAR_TO_TRAIN_REDUCTION_FACTOR,\n",
    ")\n",
    "\n",
    "train_x, train_y = train_dataset.inputs, train_dataset.outputs\n",
    "print(\"Train shapes: \", train_x.shape, train_y.shape)\n",
    "\n",
    "grid_size = train_dataset.num_cells\n",
    "print(f\"{grid_size=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = train_dataset.inputs, train_dataset.outputs\n",
    "print(\"Train shapes: \", train_x.shape, train_y.shape)\n",
    "train_size = train_x.shape[0]\n",
    "\n",
    "test_x, test_y = test_dataset.inputs, test_dataset.outputs\n",
    "print(\"Test shapes: \", test_x.shape, test_y.shape)\n",
    "test_size = test_x.shape[0]\n",
    "\n",
    "valid_x, valid_y = valid_dataset.inputs, valid_dataset.outputs\n",
    "print(\"Valid shapes: \", valid_x.shape, valid_y.shape)\n",
    "valid_size = valid_x.shape[0]\n",
    "\n",
    "size = train_size + test_size + valid_size\n",
    "print(train_size / size, test_size / size, valid_size / size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor()\n",
    "model.fit(train_x, train_y)\n",
    "# tree_text = export_text(model)\n",
    "# print(tree_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_\n",
    "for featurenum, importance in enumerate(importances):\n",
    "    featurename = train_dataset.featurenum_to_featurename(featurenum)\n",
    "    print(f\"{featurename} feature importance={importance}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation on trainset\n",
    "save_results = True\n",
    "evaluate_model(\n",
    "    model,\n",
    "    data=(train_x, train_y),\n",
    "    data_type=\"train\",\n",
    "    model_description=MODEL_DESCRIPTION,\n",
    "    save_results=save_results,\n",
    ")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# evalution on testset\n",
    "evaluate_model(\n",
    "    model,\n",
    "    data=(test_x, test_y),\n",
    "    data_type=\"test\",\n",
    "    model_description=MODEL_DESCRIPTION,\n",
    "    save_results=save_results,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cells = test_dataset.num_cells\n",
    "num_fields = len(test_dataset) // num_cells\n",
    "field_indices = list(range(num_fields))\n",
    "random.shuffle(field_indices)\n",
    "\n",
    "for field_idx in field_indices[:10]:\n",
    "    ti, ct, ws, wake_field, predicted_wake_field = (\n",
    "        test_dataset.get_parameters_for_plotting_univariate(model, field_idx)\n",
    "    )\n",
    "    plotting.plot_maps(\n",
    "        test_dataset.X_grid,\n",
    "        test_dataset.Y_grid,\n",
    "        wake_field,\n",
    "        predicted_wake_field,\n",
    "        ti,\n",
    "        ct,\n",
    "        ws,\n",
    "        error_to_plot=\"absolute\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
