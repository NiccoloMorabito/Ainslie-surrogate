{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate regression to predict the wind speed field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from src.logging_metrics import MetricsLogger\n",
    "from src.data_loaders import get_wake_dataloaders\n",
    "import src.plotting as plotting\n",
    "from src.evaluation import evaluate_model\n",
    "\n",
    "# define random seeds for Neural Networks\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "# in univariate, the batch size is a multiplier for number of cells\n",
    "# (i.e. the batch_size should be dividible by the number of cells)\n",
    "BATCH_MULTIPLIER = 8\n",
    "EPOCHS = 500\n",
    "LR = 0.0001  # before it was 0.01\n",
    "\n",
    "ACTIVATION_FUNCTION = nn.ReLU()  # TODO\n",
    "N_MAPPING = 256  # Number of Fourier features\n",
    "HIDDEN_LAYERS_UNITS = [256, 256, 256]  # before it was [128, 256, 32]\n",
    "\n",
    "FACTORS_FOLDER = \"discr_factors_x2_30_y-2_2_step0.125_TIstep0.01_CTstep0.01\"\n",
    "DATA_FOLDER = f\"../../data/{FACTORS_FOLDER}/\"\n",
    "\n",
    "#INPUT_VAR_TO_TRAIN_REDUCTION_FACTOR = {\"ti\": 32, \"ct\": 32}  # , 'x/D': 12, 'y/D': 12}\n",
    "#train_reduc_factor_string = \"training_factors=\" + \"-\".join(\n",
    "#    [f\"{k}{v}\" for k, v in INPUT_VAR_TO_TRAIN_REDUCTION_FACTOR.items()]\n",
    "#).replace(\"/\", \"\")\n",
    "INPUT_VAR_TO_TRAIN_RANGES = {'ti': [(0.15, 0.4)], 'ct': [(0.3, 0.7)]}\n",
    "train_range_string = \"training_ranges=\" + '-'.join([f\"{var}{r[0]}-{r[1]}\" for var, ranges in INPUT_VAR_TO_TRAIN_RANGES.items() for r in ranges])\n",
    "EXPERIMENT = \"extrapolation\"\n",
    "\n",
    "MODEL_NAME = (\n",
    "    f\"univariate_NeRF_{N_MAPPING}fourier-features_\"\n",
    "    f\"layers{'-'.join(str(lu) for lu in HIDDEN_LAYERS_UNITS)}_{train_range_string}\"\n",
    ")\n",
    "BEST_MODEL_PATH = f\"../../saved_models/{FACTORS_FOLDER}/{MODEL_NAME}.pt\"\n",
    "CONSIDER_WS = False\n",
    "COORDS_AS_INPUT = True  # univariate setting\n",
    "N_COORDINATES = 2  # Number of input coordinates (x and y)\n",
    "if CONSIDER_WS:\n",
    "    MODEL_NAME += \"_consider_ws\"\n",
    "    FACTORS_FOLDER = FACTORS_FOLDER.replace(\"TIstep0.01_CTstep0.01\", \"reducedTI-CT\")\n",
    "    BEST_MODEL_PATH = f\"../../saved_models/{FACTORS_FOLDER}/{MODEL_NAME}.pt\"\n",
    "print(f\"Model name: {MODEL_NAME}\")\n",
    "print(f\"Best model path: {BEST_MODEL_PATH}\")\n",
    "\n",
    "MODEL_DESCRIPTION = (\n",
    "    f\"{MODEL_NAME}_{FACTORS_FOLDER}: act. func. {ACTIVATION_FUNCTION.__class__.__name__} \"\n",
    "    + f\"(not last layer), batch multiplier {BATCH_MULTIPLIER}, {EPOCHS} epochs, lr={LR})\"\n",
    ")\n",
    "print(f\"Model description: {MODEL_DESCRIPTION}\")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nDevice: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourierLayer(nn.Module):\n",
    "    def __init__(self, n_features: int, n_mapping: int):\n",
    "        super(FourierLayer, self).__init__()\n",
    "        self.coefficients = nn.Parameter(\n",
    "            torch.randn(n_mapping, n_features)\n",
    "        )  # sampled from normal distribution with mean 0 and variance 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_proj = 2 * torch.pi * x @ self.coefficients.t()\n",
    "        out = torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class NeRF2D(nn.Module):\n",
    "    def __init__(self, n_coordinates: int, n_features: int, output_space: int):\n",
    "        super(NeRF2D, self).__init__()\n",
    "        self.fourier_layer = FourierLayer(n_coordinates, N_MAPPING)\n",
    "        layer_units = [N_MAPPING * 2 + n_features] + HIDDEN_LAYERS_UNITS\n",
    "        mlp_layers = list()\n",
    "        for first, second in zip(layer_units, layer_units[1:]):\n",
    "            mlp_layers += [nn.Linear(first, second), ACTIVATION_FUNCTION]\n",
    "        mlp_layers.append(\n",
    "            nn.Linear(layer_units[-1], output_space)\n",
    "        )  # last layer not activated\n",
    "        self.mlp = nn.Sequential(*mlp_layers)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Pass coordinates through the Fourier Layer\n",
    "        coords = inputs[:, -2:]\n",
    "        input_features = inputs[:, :-2]\n",
    "        fourier_out = self.fourier_layer(coords)\n",
    "\n",
    "        # Concatenate Fourier layer output with other input features\n",
    "        input_features = torch.cat((fourier_out, input_features), dim=-1)\n",
    "\n",
    "        # Feed-forward through the rest of the neural network\n",
    "        x = self.mlp(input_features)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataloader = None\n",
    "train_dataloader, valid_dataloader, test_dataloader = get_wake_dataloaders(\n",
    "    DATA_FOLDER,\n",
    "    consider_ws=CONSIDER_WS,\n",
    "    coords_as_input=COORDS_AS_INPUT,\n",
    "    # train_perc=0.6,\n",
    "    # test_perc=0.2,\n",
    "    # validation_perc=0.2,\n",
    "    #input_var_to_train_reduction_factor=INPUT_VAR_TO_TRAIN_REDUCTION_FACTOR,\n",
    "    input_var_to_train_ranges=INPUT_VAR_TO_TRAIN_RANGES,\n",
    "    batch_multiplier=BATCH_MULTIPLIER,\n",
    ")\n",
    "len(train_dataloader)\n",
    "print(valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in train_dataloader:\n",
    "    print(b[0].shape, b[1].shape)\n",
    "    break\n",
    "\n",
    "input_space = train_dataloader.dataset.inputs.shape[1]\n",
    "n_features = input_space - N_COORDINATES\n",
    "output_space = train_dataloader.dataset.outputs.shape[1]\n",
    "print(\n",
    "    f\"{input_space=} ({N_COORDINATES} coordinates and {n_features} other input features)\\t{output_space=}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeRF2D(N_COORDINATES, n_features, output_space).to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam((p for p in model.parameters() if p.requires_grad), lr=LR)\n",
    "loss_function = torch.nn.MSELoss()\n",
    "\n",
    "metrics_logger = MetricsLogger(name=MODEL_NAME, automatic_save_after=2)\n",
    "best_vloss = 1_000_000.0\n",
    "for epoch in range(EPOCHS):\n",
    "    \"\"\"TRAINING\"\"\"\n",
    "    model.train(True)\n",
    "    epoch_tloss = 0\n",
    "    for batch in iter(train_dataloader):\n",
    "        x, y = batch[0].to(DEVICE), batch[1].to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(x)\n",
    "        tloss = loss_function(prediction, y)\n",
    "        tloss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) TODO\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_tloss += tloss.item() * x.size(0)\n",
    "        # TODO accuracy or other metric computation????\n",
    "\n",
    "    avg_tloss = epoch_tloss / len(train_dataloader.sampler)\n",
    "    metrics_logger.log_metric(epoch, \"Training loss\", avg_tloss)\n",
    "\n",
    "    \"\"\"VALIDATION\"\"\"\n",
    "    if valid_dataloader:\n",
    "        model.train(False)\n",
    "        epoch_vloss = 0\n",
    "        for batch in iter(valid_dataloader):\n",
    "            x, y = batch[0].to(DEVICE), batch[1].to(DEVICE)\n",
    "            prediction = model(x)\n",
    "            vloss = loss_function(prediction, y)\n",
    "\n",
    "            epoch_vloss += vloss.item() * x.size(0)\n",
    "\n",
    "        avg_vloss = epoch_vloss / len(valid_dataloader.sampler)\n",
    "        metrics_logger.log_metric(epoch, \"Validation loss\", avg_vloss)\n",
    "        # Track best performance, and save the model's state\n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_vloss\n",
    "            torch.save(model.state_dict(), BEST_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_logger.plot_metrics_by_epoch(start_from_epoch=2)\n",
    "metrics_logger.save_metrics()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading best model\n",
    "model = NeRF2D(N_COORDINATES, n_features, output_space).to(DEVICE)\n",
    "model.load_state_dict(torch.load(BEST_MODEL_PATH))\n",
    "model.eval()\n",
    "\n",
    "save_results = True\n",
    "\n",
    "# evaluation on trainset\n",
    "evaluate_model(\n",
    "    model,\n",
    "    data=train_dataloader,\n",
    "    data_type=\"train\",\n",
    "    model_description=MODEL_DESCRIPTION,\n",
    "    save_results=save_results,\n",
    "    experiment=EXPERIMENT,\n",
    ")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# evalution on testset\n",
    "evaluate_model(\n",
    "    model,\n",
    "    data=test_dataloader,\n",
    "    data_type=\"test\",\n",
    "    model_description=MODEL_DESCRIPTION,\n",
    "    save_results=save_results,\n",
    "    experiment=EXPERIMENT,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataloader.dataset\n",
    "num_cells = test_dataset.num_cells\n",
    "num_fields = len(test_dataset) // num_cells\n",
    "field_indices = list(range(num_fields))\n",
    "#random.shuffle(field_indices)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for field_idx in field_indices[2935:2940]:\n",
    "        ti, ct, ws, wake_field, predicted_wake_field = (\n",
    "            test_dataset.get_parameters_for_plotting_univariate(model, field_idx)\n",
    "        )\n",
    "        plotting.plot_maps(\n",
    "            test_dataset.X_grid,\n",
    "            test_dataset.Y_grid,\n",
    "            wake_field,\n",
    "            predicted_wake_field,\n",
    "            ti,\n",
    "            ct,\n",
    "            ws,\n",
    "            error_to_plot=\"absolute\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
