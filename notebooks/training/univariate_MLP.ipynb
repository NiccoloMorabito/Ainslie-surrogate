{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate regression to predict the wind speed field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from src.logging_metrics import MetricsLogger\n",
    "from src.data_loaders import get_wake_dataloaders\n",
    "import src.plotting as plotting\n",
    "from src.evaluation import evaluate_model\n",
    "\n",
    "# define random seeds for Neural Networks\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_LAYERS_UNITS = [50, 250]\n",
    "ACTIVATION_FUNCTION = nn.ReLU()\n",
    "\n",
    "\n",
    "class UnivariateNN(nn.Module):\n",
    "    def __init__(self, input_space, output_space) -> None:\n",
    "        super(UnivariateNN, self).__init__()\n",
    "        layer_units = [input_space] + HIDDEN_LAYERS_UNITS\n",
    "        layers = list()\n",
    "        for first, second in zip(layer_units, layer_units[1:]):\n",
    "            layers += [nn.Linear(first, second), ACTIVATION_FUNCTION]\n",
    "        layers.append(\n",
    "            nn.Linear(layer_units[-1], output_space)\n",
    "        )  # last layer not activated\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACTORS_FOLDER = \"discr_factors_x2_30_y-2_2_step0.125_TIstep0.01_CTstep0.01\"\n",
    "DATA_FOLDER = f\"../../data/{FACTORS_FOLDER}/\"\n",
    "\n",
    "INPUT_VAR_TO_TRAIN_REDUCTION_FACTOR = {\"ti\": 4, \"ct\": 4}  # , 'x/D': 4, 'y/D': 4}\n",
    "train_reduc_factor_string = \"training_factors=\" + \"-\".join(\n",
    "    [f\"{k}{v}\" for k, v in INPUT_VAR_TO_TRAIN_REDUCTION_FACTOR.items()]\n",
    ").replace(\"/\", \"\")\n",
    "# INPUT_VAR_TO_TRAIN_RANGES = {\"ti\": [(0.15, 0.4)], \"ct\": [(0.3, 0.7)]}\n",
    "# train_range_string = \"training_ranges=\" + \"-\".join(\n",
    "#    [\n",
    "#        f\"{var}{r[0]}-{r[1]}\"\n",
    "#        for var, ranges in INPUT_VAR_TO_TRAIN_RANGES.items()\n",
    "#        for r in ranges\n",
    "#    ]\n",
    "# )\n",
    "EXPERIMENT = \"interpolation\"\n",
    "MODEL_NAME = f\"univariate_NN_layers{'-'.join(str(lu) for lu in HIDDEN_LAYERS_UNITS)}_{train_reduc_factor_string}\"\n",
    "BEST_MODEL_PATH = f\"../../saved_models/{FACTORS_FOLDER}/{MODEL_NAME}.pt\"\n",
    "CONSIDER_WS = False\n",
    "COORDS_AS_INPUT = True  # univariate setting\n",
    "if CONSIDER_WS:\n",
    "    MODEL_NAME += \"_consider_ws\"\n",
    "    BEST_MODEL_PATH = BEST_MODEL_PATH.replace(\"TIstep0.01_CTstep0.01\", \"reducedTI-CT\")\n",
    "print(f\"Model name: {MODEL_NAME}\")\n",
    "print(f\"Best model path: {BEST_MODEL_PATH}\")\n",
    "\n",
    "# hyperparameters\n",
    "# in univariate, the batch size is a multiplier for number of cells\n",
    "# (i.e. the batch_size should be dividible by the number of cells)\n",
    "BATCH_MULTIPLIER = 8\n",
    "EPOCHS = 500\n",
    "LR = 1e-05\n",
    "\n",
    "MODEL_DESCRIPTION = (\n",
    "    f\"{MODEL_NAME}_{FACTORS_FOLDER}: act. func. {ACTIVATION_FUNCTION.__class__.__name__} \"\n",
    "    + f\"(not last layer), batch multiplier {BATCH_MULTIPLIER}, {EPOCHS} epochs, lr={LR})\"\n",
    ")\n",
    "\n",
    "print(f\"Model description: {MODEL_DESCRIPTION}\")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nDevice: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataloader = None\n",
    "train_dataloader, valid_dataloader, test_dataloader = get_wake_dataloaders(\n",
    "    DATA_FOLDER,\n",
    "    consider_ws=CONSIDER_WS,\n",
    "    coords_as_input=COORDS_AS_INPUT,\n",
    "    # train_perc=0.6,\n",
    "    # test_perc=0.2,\n",
    "    # validation_perc=0.2,\n",
    "    input_var_to_train_reduction_factor=INPUT_VAR_TO_TRAIN_REDUCTION_FACTOR,\n",
    "    # input_var_to_train_ranges=INPUT_VAR_TO_TRAIN_RANGES,\n",
    "    batch_multiplier=BATCH_MULTIPLIER,\n",
    ")\n",
    "len(train_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in train_dataloader:\n",
    "    print(b[0].shape, b[1].shape)\n",
    "    break\n",
    "\n",
    "input_space = train_dataloader.dataset.inputs.shape[1]\n",
    "output_space = train_dataloader.dataset.outputs.shape[1]\n",
    "print(f\"{input_space=}\\t{output_space=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UnivariateNN(input_space, output_space).to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam((p for p in model.parameters() if p.requires_grad), lr=LR)\n",
    "loss_function = torch.nn.MSELoss()\n",
    "\n",
    "metrics_logger = MetricsLogger(name=MODEL_NAME)\n",
    "best_vloss = 1_000_000.0\n",
    "for epoch in range(EPOCHS):\n",
    "    \"\"\"TRAINING\"\"\"\n",
    "    model.train(True)\n",
    "    epoch_tloss = 0\n",
    "    for batch in iter(train_dataloader):\n",
    "        x, y = batch[0].to(DEVICE), batch[1].to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(x)\n",
    "        tloss = loss_function(prediction, y)\n",
    "        tloss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_tloss += tloss.item() * x.size(0)\n",
    "\n",
    "    avg_tloss = epoch_tloss / len(train_dataloader.sampler)\n",
    "    metrics_logger.log_metric(epoch, \"Training loss\", avg_tloss)\n",
    "\n",
    "    \"\"\"VALIDATION\"\"\"\n",
    "    if valid_dataloader:\n",
    "        model.train(False)\n",
    "        epoch_vloss = 0\n",
    "        for batch in iter(valid_dataloader):\n",
    "            x, y = batch[0].to(DEVICE), batch[1].to(DEVICE)\n",
    "            prediction = model(x)\n",
    "            vloss = loss_function(prediction, y)\n",
    "\n",
    "            epoch_vloss += vloss.item() * x.size(0)\n",
    "\n",
    "        avg_vloss = epoch_vloss / len(valid_dataloader.sampler)\n",
    "        metrics_logger.log_metric(epoch, \"Validation loss\", avg_vloss)\n",
    "        # Track best performance, and save the model's state\n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_vloss\n",
    "            torch.save(model.state_dict(), BEST_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_logger.plot_metrics_by_epoch()\n",
    "metrics_logger.save_metrics()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading best model\n",
    "model = UnivariateNN(input_space, output_space).to(DEVICE)\n",
    "model.load_state_dict(torch.load(BEST_MODEL_PATH))\n",
    "model.eval()\n",
    "\n",
    "save_results = False\n",
    "\n",
    "\"\"\"\n",
    "# evaluation on trainset\n",
    "evaluate_model(\n",
    "    model,\n",
    "    data=train_dataloader,\n",
    "    data_type=\"train\",\n",
    "    model_description=MODEL_DESCRIPTION,\n",
    "    save_results=save_results,\n",
    "    experiment=EXPERIMENT,\n",
    ")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# evalution on testset\n",
    "evaluate_model(\n",
    "    model,\n",
    "    data=test_dataloader,\n",
    "    data_type=\"test\",\n",
    "    model_description=MODEL_DESCRIPTION,\n",
    "    save_results=save_results,\n",
    "    experiment=EXPERIMENT,\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataloader.dataset\n",
    "num_cells = test_dataset.num_cells\n",
    "num_fields = len(test_dataset) // num_cells\n",
    "field_indices = list(range(num_fields))\n",
    "random.shuffle(field_indices)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for field_idx in field_indices[:10]:\n",
    "        ti, ct, ws, wake_field, predicted_wake_field = (\n",
    "            test_dataset.get_parameters_for_plotting_univariate(model, field_idx)\n",
    "        )\n",
    "\n",
    "        plotting.plot_maps(\n",
    "            test_dataset.X_grid,\n",
    "            test_dataset.Y_grid,\n",
    "            wake_field,\n",
    "            predicted_wake_field,\n",
    "            ti,\n",
    "            ct,\n",
    "            ws,\n",
    "            error_to_plot=\"signed percentage\",\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
