{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import time\n",
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "from py_wake.deficit_models import EddyViscosityModel\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import src.utils as utils\n",
    "import src.pywake_utils as py_wake_utils\n",
    "from src.data_utils import load_netcfd\n",
    "import src.data_utils as data_utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discretization parameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFICIT_THRESHOLD = 1 / 100  # putting it to 1/1000, the region becomes too big\n",
    "\n",
    "X_START_FACTOR = 2\n",
    "X_END_FACTOR = 50\n",
    "Y_START_FACTOR = -10\n",
    "Y_END_FACTOR = 10\n",
    "GRID_STEP_FACTOR = 1 / 8\n",
    "\n",
    "TURBINE_DIAMETER = 198\n",
    "TURBINE_HUB_HEIGHT = 119\n",
    "TURBINE_POWER_NORM = 10000\n",
    "TURBINE_X = [0]\n",
    "TURBINE_Y = [0]\n",
    "\n",
    "WS_RANGE = range(10, 26)\n",
    "WIND_DIRECTION = 270\n",
    "TI_STEP = 0.01\n",
    "CT_STEP = 0.01\n",
    "TIs = utils.my_arange(0, 1, TI_STEP)  # the ti is percentage\n",
    "CTs = utils.my_arange(0.1, 24 / 25, CT_STEP)\n",
    "\n",
    "\n",
    "horizontal_grid = py_wake_utils.get_discretized_grid(\n",
    "    TURBINE_DIAMETER,\n",
    "    X_START_FACTOR,\n",
    "    X_END_FACTOR,\n",
    "    Y_START_FACTOR,\n",
    "    Y_END_FACTOR,\n",
    "    GRID_STEP_FACTOR,\n",
    ")\n",
    "\n",
    "x_ranges = []\n",
    "y_ranges = []\n",
    "\n",
    "for wind_speed in random.sample(list(WS_RANGE), 5):\n",
    "    for ti, ct in random.sample(sorted(itertools.product(TIs, CTs)), 200):\n",
    "        # print(f\"{wind_speed=}\\t{ti=}\\t{ct=}\")\n",
    "        site = py_wake_utils.get_site(ti=ti, ws=wind_speed)\n",
    "        wind_turbine = py_wake_utils.get_wind_turbine(\n",
    "            TURBINE_DIAMETER,\n",
    "            TURBINE_HUB_HEIGHT,\n",
    "            TURBINE_POWER_NORM,\n",
    "            constant_ct=ct,\n",
    "            ti=ti,\n",
    "        )\n",
    "\n",
    "        # single wake model\n",
    "        ainslie_model = EddyViscosityModel(site, wind_turbine)\n",
    "\n",
    "        df = (\n",
    "            py_wake_utils.generate_wake_dataset(\n",
    "                ainslie_model,\n",
    "                wind_speed,\n",
    "                WIND_DIRECTION,\n",
    "                TURBINE_DIAMETER,\n",
    "                TURBINE_X,\n",
    "                TURBINE_Y,\n",
    "                horizontal_grid,\n",
    "                wind_turbine,\n",
    "            )\n",
    "            .to_dataframe()\n",
    "            .reset_index()\n",
    "            .rename(columns={\"x:D\": \"x/D\", \"y:D\": \"y/D\"})\n",
    "            .sort_values(by=[\"x/D\", \"y/D\"])\n",
    "        )\n",
    "\n",
    "        filtered_df = df[df[\"wind_deficit\"] > DEFICIT_THRESHOLD]\n",
    "        if filtered_df.empty:\n",
    "            utils.plotting.plot_deficit_map(df)\n",
    "            continue\n",
    "\n",
    "        x_range = np.nanmin(filtered_df[\"x/D\"]), np.nanmax(filtered_df[\"x/D\"])\n",
    "        y_range = np.nanmin(filtered_df[\"y/D\"]), np.nanmax(filtered_df[\"y/D\"])\n",
    "\n",
    "        # print(\"Range of x/D:\", x_range)\n",
    "        # print(\"Range of y/D:\", y_range)\n",
    "        x_ranges.append(x_range)\n",
    "        y_ranges.append(y_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "x_ends = sorted([x_range[1] for x_range in x_ranges])\n",
    "print(\n",
    "    f\"For x-end, min is: {min(x_ends)} and max is: {max(x_ends)},\"\n",
    "    + f\" with an average of {sum(x_ends) / len(x_ends)} and a median of {statistics.median(x_ends)}\"\n",
    ")\n",
    "\n",
    "y_starts = sorted([y_range[0] for y_range in y_ranges])\n",
    "print(\n",
    "    f\"For y-start, min is: {min(y_starts)} and max is: {max(y_starts)},\"\n",
    "    + f\" with an average of {sum(y_starts) / len(y_starts)} and a median of {statistics.median(y_starts)}\"\n",
    ")\n",
    "y_ends = sorted([y_range[1] for y_range in y_ranges])\n",
    "print(\n",
    "    f\"For y-end, min is: {min(y_ends)} and max is: {max(y_ends)},\"\n",
    "    + f\" with an average of {sum(y_ends) / len(y_ends)} and a median of {statistics.median(y_ends)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Ainslie-generated dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"data/discr_factors_x2_30_y-2_2_step0.125_TIstep0.01_CTstep0.01\"\n",
    "total_data = list()\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    wind_speed = int(file.split(\".nc\")[0].split(\"ws_\")[1])\n",
    "    df = load_netcfd(\n",
    "        folder,\n",
    "        wind_speed,\n",
    "        include_ws_column=True,\n",
    "        input_var_to_reduction_factor={\n",
    "            \"ti\": 4,\n",
    "            \"ct\": 4,\n",
    "        },\n",
    "    )\n",
    "    df.drop(\"WS_eff\", axis=1, inplace=True)\n",
    "    df.rename({\"ti\": \"TI\", \"ct\": \"C_T\", \"wind_deficit\": \"wd\"}, axis=1, inplace=True)\n",
    "    total_data.append(df)\n",
    "\n",
    "total_data = pd.concat(total_data)\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = total_data.corr()\n",
    "\n",
    "# Plot a heatmap to visualize the correlation\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "# plt.title(\"Correlation Matrix of Input Features and Wind Deficit\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "folder = \"data/discr_factors_x2_30_y-2_2_step0.125_TIstep0.01_CTstep0.01\"\n",
    "aggregated_data = pd.DataFrame()\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    wind_speed = int(file.split(\".nc\")[0].split(\"ws_\")[1])\n",
    "    df = load_netcfd(folder, wind_speed, include_ws_column=True)\n",
    "    \n",
    "    # Compute the desired statistics for each file and append them to the aggregated DataFrame\n",
    "    statistics = df.mean()  # Replace this with your desired statistics calculation\n",
    "    aggregated_data = aggregated_data.append(statistics, ignore_index=True)\n",
    "\n",
    "# Calculate the correlation matrix for the aggregated data\n",
    "correlation_matrix = aggregated_data.corr()\n",
    "\n",
    "# Plot a heatmap to visualize the correlation\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deficit statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation\n",
    "folder = \"data/discr_factors_x2_30_y-2_2_step0.125_TIstep0.01_CTstep0.01\"\n",
    "\n",
    "ws_to_metrics = dict()\n",
    "tict_to_ws_to_deficitmetrics = dict()\n",
    "deficits = list()\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    wind_speed = int(file.split(\".nc\")[0].split(\"ws_\")[1])\n",
    "    df = load_netcfd(\n",
    "        folder, wind_speed, include_ws_column=True\n",
    "    )  # , ti_range=(0, 0.5), ct_range=(0, 0.5),\n",
    "    # input_var_to_reduction_factor={'ti': 3, 'ct': 5})\n",
    "\n",
    "    deficitmean = df.wind_deficit.mean()\n",
    "    deficitmin = df.wind_deficit.min()\n",
    "    deficitmax = df.wind_deficit.max()\n",
    "    deficitmedian = df.wind_deficit.median()\n",
    "    ws_to_metrics[wind_speed] = [deficitmin, deficitmean, deficitmedian, deficitmax]\n",
    "\n",
    "    print(deficitmin, deficitmax, deficitmean, deficitmedian)\n",
    "    plt.boxplot(df.wind_deficit)\n",
    "    plt.xlabel(\"wind deficit\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.ylim(0, 0.2)\n",
    "    plt.show()\n",
    "\n",
    "    sns.violinplot(y=df.wind_deficit)\n",
    "    plt.ylabel(\"wind deficit\")\n",
    "    plt.ylim(0, 0.2)\n",
    "    plt.show()\n",
    "    break\n",
    "\n",
    "    \"\"\"\n",
    "    for inputs, subdf in df.groupby([\"ti\", \"ct\", \"ws\"]):\n",
    "        #assert subdf.shape[0] == 7168\n",
    "        tict = \"{:.2f}_{:.2f}\".format(inputs[0], inputs[1])\n",
    "        ws = inputs[2]\n",
    "        deficitmean = subdf.wind_deficit.mean()\n",
    "        deficitmin = subdf.wind_deficit.min()\n",
    "        deficitmax = subdf.wind_deficit.max()\n",
    "        deficitmedian = subdf.wind_deficit.median()\n",
    "        #print(tict, ws, deficitmean)\n",
    "        if tict not in tict_to_ws_to_deficitmetrics.keys():\n",
    "            tict_to_ws_to_deficitmetrics[tict] = dict()\n",
    "        tict_to_ws_to_deficitmetrics[tict][ws] = [deficitmin, deficitmean, deficitmedian, deficitmax]\n",
    "    \"\"\"\n",
    "\n",
    "print(len(tict_to_ws_to_deficitmetrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deficits = np.array(deficits)\n",
    "print(deficits.min(), deficits.max(), deficits.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Deficit statistics over wind speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the maximum deficit value\n",
    "for ws, metrics in ws_to_metrics.items():\n",
    "    print(\n",
    "        f\"for {ws=} \\t-> mean={metrics[0]}, median={metrics[2]}, min={metrics[1]}, max={metrics[-1]}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_data = sorted(ws_to_metrics.items())\n",
    "\n",
    "# Extract sorted keys and values\n",
    "x = [key for key, _ in sorted_data]\n",
    "ys = [[value[i] for _, value in sorted_data] for i in range(4)]\n",
    "\n",
    "colors = [\"red\", \"grey\", \"blue\", \"green\"]\n",
    "labels = [\"min\", \"mean\", \"median\", \"max\"]\n",
    "for i, y in enumerate(ys):\n",
    "    plt.plot(x, y, marker=\"^\", color=colors[i], label=labels[i])\n",
    "plt.xlabel(\"Wind speed (m/s)\")\n",
    "plt.ylabel(\"Wind deficit\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deficit statistics over wind speed per TI-CT combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_ticts = random.sample(tict_to_ws_to_deficitmetrics.items(), 5)\n",
    "\n",
    "for tict, ws_to_deficitmetrics in selected_ticts:\n",
    "    print(tict)\n",
    "    sorted_data = sorted(ws_to_deficitmetrics.items())\n",
    "\n",
    "    # Extract sorted keys and values\n",
    "    x = [key for key, _ in sorted_data]\n",
    "    ys = [[value[i] for _, value in sorted_data] for i in range(4)]\n",
    "\n",
    "    colors = [\"red\", \"grey\", \"blue\", \"green\"]\n",
    "    labels = [\"min\", \"mean\", \"median\", \"max\"]\n",
    "    for i, y in enumerate(ys):\n",
    "        plt.plot(x, y, marker=\"^\", color=colors[i], label=labels[i])\n",
    "    plt.xlabel(\"Wind speed (m/s)\")\n",
    "    plt.ylabel(\"Wind deficit\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance (from Decision Tree results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_to_importance = {\n",
    "    \"TI\": 0.21651978373434827,\n",
    "    \"C_T\": 0.20347379365589874,\n",
    "    \"ws\": 2.269498858710338e-18,\n",
    "    \"x/D\": 0.14726651526616422,\n",
    "    \"y/D\": 0.4327399073435887,\n",
    "}\n",
    "\n",
    "colors = [\"skyblue\", \"lightgreen\", \"salmon\", \"lightcoral\", \"lightpink\"]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(feature_to_importance.keys(), feature_to_importance.values(), color=colors)\n",
    "\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Feature Importance\")\n",
    "# plt.title('Feature Importance of Decision Tree Regressor')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time comparison between pywake and my model simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define random seeds for Neural Networks\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# default parameters\n",
    "TURBINE_X = [0]\n",
    "TURBINE_Y = [0]\n",
    "WIND_DIRECTION = 270\n",
    "\n",
    "# IEA37 values\n",
    "TURBINE_DIAMETER = 198\n",
    "TURBINE_HUB_HEIGHT = 119\n",
    "TURBINE_POWER_NORM = 10000\n",
    "\n",
    "# discretization factors\n",
    "X_START_FACTOR = 2\n",
    "X_END_FACTOR = 20\n",
    "Y_START_FACTOR = -5\n",
    "Y_END_FACTOR = 5\n",
    "GRID_STEP_FACTOR = 1 / 8\n",
    "\n",
    "# parameters for data generation\n",
    "WS_RANGE = range(3, 26)\n",
    "TI_STEP = 0.01\n",
    "CT_STEP = 0.01\n",
    "TIs = utils.my_arange(0, 1, TI_STEP)\n",
    "CTs = utils.my_arange(0.2, 24 / 25, CT_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_grid = py_wake_utils.get_discretized_grid(\n",
    "    TURBINE_DIAMETER,\n",
    "    X_START_FACTOR,\n",
    "    X_END_FACTOR,\n",
    "    Y_START_FACTOR,\n",
    "    Y_END_FACTOR,\n",
    "    GRID_STEP_FACTOR,\n",
    ")\n",
    "\n",
    "ws_to_list = dict()\n",
    "for wind_speed in WS_RANGE:\n",
    "    datasets = list()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for ti, ct in itertools.product(TIs, CTs):\n",
    "        site = py_wake_utils.get_site(ti=ti, ws=wind_speed)\n",
    "        wind_turbine = py_wake_utils.get_wind_turbine(\n",
    "            TURBINE_DIAMETER,\n",
    "            TURBINE_HUB_HEIGHT,\n",
    "            TURBINE_POWER_NORM,\n",
    "            constant_ct=ct,\n",
    "            ti=ti,\n",
    "        )\n",
    "\n",
    "        # single wake model\n",
    "        ainslie_model = EddyViscosityModel(site, wind_turbine)\n",
    "\n",
    "        ds = py_wake_utils.generate_wake_dataset(\n",
    "            ainslie_model,\n",
    "            wind_speed,\n",
    "            WIND_DIRECTION,\n",
    "            TURBINE_DIAMETER,\n",
    "            TURBINE_X,\n",
    "            TURBINE_Y,\n",
    "            horizontal_grid,\n",
    "            wind_turbine,\n",
    "        )\n",
    "        datasets.append(ds)\n",
    "\n",
    "    filepath = data_utils.get_filepath(\n",
    "        X_START_FACTOR,\n",
    "        X_END_FACTOR,\n",
    "        Y_START_FACTOR,\n",
    "        Y_END_FACTOR,\n",
    "        GRID_STEP_FACTOR,\n",
    "        wind_speed,\n",
    "        TI_STEP,\n",
    "        CT_STEP,\n",
    "    )\n",
    "    final_ds = xr.concat(\n",
    "        [d.stack(z=[\"x:D\", \"y:D\", \"ti\", \"ct\"]) for d in datasets], \"z\"\n",
    "    ).unstack(\"z\")\n",
    "    cacca = final_ds.load()\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    num_simulations = len(datasets)\n",
    "    print(\n",
    "        f\"For {wind_speed=}] Execution time: {execution_time} seconds for {num_simulations} simulations -> {(execution_time/num_simulations):2f}s per simulation\"\n",
    "    )\n",
    "    ws_to_list[wind_speed] = [num_simulations, execution_time]\n",
    "\n",
    "tot_simulations = sum([num_sim for num_sim, _ in ws_to_list.values()])\n",
    "tot_time = sum([ex_time for _, ex_time in ws_to_list.values()])\n",
    "print(\n",
    "    f\"\\nOverall execution time for {tot_simulations} simulations: {tot_time} seconds -> {tot_time/tot_simulations:2f}s per simulation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"saved_models/discr_factors_x2_20_y-5_5_step0.125_TIstep0.01_CTstep0.01/multivariate_NN_layers50-500-2500.pt\"\n",
    "HIDDEN_LAYERS_UNITS = [\n",
    "    int(lu) for lu in MODEL_PATH.split(\"layers\")[-1].split(\".pt\")[0].split(\"-\")\n",
    "]\n",
    "\n",
    "\n",
    "class MultivariateNN(nn.Module):\n",
    "    def __init__(self, input_space, output_space) -> None:\n",
    "        super(MultivariateNN, self).__init__()\n",
    "        layer_units = [input_space] + HIDDEN_LAYERS_UNITS + [output_space]\n",
    "        layers = []\n",
    "        for first, second in zip(layer_units, layer_units[1:]):\n",
    "            layers += [nn.Linear(first, second), nn.ReLU()]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "model = MultivariateNN(2, 11520)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model.eval()\n",
    "\n",
    "ws_to_list = dict()\n",
    "with torch.no_grad():\n",
    "    for wind_speed in WS_RANGE:\n",
    "        datasets = []\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        for ti, ct in itertools.product(TIs, CTs):\n",
    "            wake_field = model(torch.FloatTensor([ti, ct]))\n",
    "            datasets.append(wake_field)\n",
    "\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        num_simulations = len(datasets)\n",
    "        print(\n",
    "            f\"For {wind_speed=}] Execution time: {execution_time} seconds for {num_simulations} simulations -> {(execution_time/num_simulations):2f}s per simulation\"\n",
    "        )\n",
    "        ws_to_list[wind_speed] = [num_simulations, execution_time]\n",
    "\n",
    "tot_simulations = sum(num_sim for num_sim, _ in ws_to_list.values())\n",
    "tot_time = sum(ex_time for _, ex_time in ws_to_list.values())\n",
    "print(\n",
    "    f\"\\nOverall execution time for {tot_simulations} simulations: {tot_time} seconds -> {tot_time/tot_simulations:2f}s per simulation\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of \"Evaluation of 3 potential ML algorithms\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/Evaluation of three potential ML algorithms - train-test.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = data[\"s (x/D)\"].unique()\n",
    "Ys = data[\"r\"].unique()\n",
    "shape = len(Xs), len(Ys)\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_LABEL = \"s (x/D)\"\n",
    "Y_LABEL = \"r\"  # or 'r/R\n",
    "Z_LABEL = \"Velocity\"\n",
    "GROUPBY = \"Wind speed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contour(\n",
    "    X,\n",
    "    Y,\n",
    "    Z,\n",
    "    xlabel: str,\n",
    "    ylabel: str,\n",
    "    zlabel: str,\n",
    "    title: str,\n",
    "    levels=500,\n",
    "    cmap: str = \"Blues\",\n",
    "    ax=None,\n",
    ") -> None:\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    c = ax.contourf(X, Y, Z, levels=levels, cmap=cmap)\n",
    "    plt.colorbar(c, label=zlabel, ax=ax)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for wind_speed, subdf in data.groupby(GROUPBY):\n",
    "    assert not subdf[[X_LABEL, Y_LABEL]].duplicated().any()\n",
    "    X, Y = np.meshgrid(subdf[X_LABEL].unique(), subdf[Y_LABEL].unique())\n",
    "    Z = subdf.pivot(index=Y_LABEL, columns=X_LABEL, values=\"Velocity\").values\n",
    "    plot_contour(X, Y, Z, X_LABEL, Y_LABEL, Z_LABEL, title=f\"Wind speed: {wind_speed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for wind_speed, subdf in data.groupby(GROUPBY):\n",
    "    s_values = subdf[X_LABEL]\n",
    "    r_values = subdf[Y_LABEL]\n",
    "    velocity_values = subdf[Z_LABEL]\n",
    "\n",
    "    X, Y = np.meshgrid(s_values.unique(), r_values.unique())\n",
    "\n",
    "    # Create an empty 2D array for counter values\n",
    "    counter_values = np.zeros_like(X)\n",
    "\n",
    "    # Fill the counter values array with corresponding velocity values\n",
    "    for s, r, velocity in zip(s_values, r_values, velocity_values):\n",
    "        s_index = np.where(X[0] == s)[0][0]\n",
    "        r_index = np.where(Y[:, 0] == r)[0][0]\n",
    "        counter_values[r_index, s_index] = velocity\n",
    "\n",
    "    plot_contour(\n",
    "        X,\n",
    "        Y,\n",
    "        counter_values,\n",
    "        X_LABEL,\n",
    "        Y_LABEL,\n",
    "        Z_LABEL,\n",
    "        title=f\"Counter Map - Wind Speed: {wind_speed}\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
