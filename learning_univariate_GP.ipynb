{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "import torch\n",
    "\n",
    "from utils.data_loaders import get_wake_datasets\n",
    "from utils.evaluation import evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model description: univariate_skGP_training_factors=ti4-ct4_discr_factors_x2_30_y-2_2_step0.125_TIstep0.01_CTstep0.01 standard multivariate GP\n",
      "DEVICE=device(type='cpu')\n"
     ]
    }
   ],
   "source": [
    "FACTORS_FOLDER = \"discr_factors_x2_30_y-2_2_step0.125_TIstep0.01_CTstep0.01\"\n",
    "DATA_FOLDER = f\"data/{FACTORS_FOLDER}/\"\n",
    "INPUT_VAR_TO_TRAIN_REDUCTION_FACTOR = {'ti': 4, 'ct': 4}\n",
    "train_reduc_factor_string = \"training_factors=\" + \"-\".join([f\"{k}{v}\" for k, v in INPUT_VAR_TO_TRAIN_REDUCTION_FACTOR.items()])\n",
    "MODEL_NAME = f\"univariate_skGP_{train_reduc_factor_string}\"\n",
    "#BEST_MODEL_PATH = f\"saved_models/{FACTORS_FOLDER}/{MODEL_NAME}.pt\"\n",
    "CONSIDER_WS = False\n",
    "COORDS_AS_INPUT = True # univariate setting\n",
    "\n",
    "if CONSIDER_WS:\n",
    "    MODEL_NAME += \"_consider_ws\"\n",
    "    FACTORS_FOLDER = FACTORS_FOLDER.replace(\"TIstep0.01_CTstep0.01\", \"reducedTI-CT\")\n",
    "    BEST_MODEL_PATH = f\"saved_models/{FACTORS_FOLDER}/{MODEL_NAME}.pt\"\n",
    "\n",
    "MODEL_DESCRIPTION = f\"{MODEL_NAME}_{FACTORS_FOLDER} standard multivariate GP\" #TODO\n",
    "print(f\"Model description: {MODEL_DESCRIPTION}\")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"{DEVICE=}\")\n",
    "\n",
    "# hyperparameters\n",
    "#EPOCHS = 2 #TODO\n",
    "#LR = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niccolomorabito/Library/CloudStorage/GoogleDrive-morabito.1808746@studenti.uniroma1.it/My Drive/BDMA/Semester4 Thesis/Ainslie-surrogate/utils/data_loaders.py:230: UserWarning: \n",
      "Ignoring percentages of train-valid-test split (train_perc=0.8, valid_perc=0, test_perc=0.2)\n",
      "and using the reduction factors for the training set instead:\n",
      "{'ti': 4, 'ct': 4}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes:  torch.Size([3942400, 4]) torch.Size([3942400])\n",
      "Test shapes:  torch.Size([28851200, 4]) torch.Size([28851200])\n",
      "Valid shapes:  torch.Size([28851200, 4]) torch.Size([28851200])\n"
     ]
    }
   ],
   "source": [
    "valid_dataset = None\n",
    "train_dataset, valid_dataset, test_dataset = get_wake_datasets(DATA_FOLDER,\n",
    "                                                          consider_ws=CONSIDER_WS,\n",
    "                                                          coords_as_input=COORDS_AS_INPUT,\n",
    "                                                          #train_perc=0.6,\n",
    "                                                          #test_perc=0.3,\n",
    "                                                          #validation_perc=0.1\n",
    "                                                          input_var_to_train_reduction_factor=INPUT_VAR_TO_TRAIN_REDUCTION_FACTOR)\n",
    "\n",
    "train_x, train_y = train_dataset.inputs, train_dataset.outputs.view(-1)\n",
    "test_x, test_y = test_dataset.inputs, test_dataset.outputs.view(-1)\n",
    "print(\"Train shapes: \", train_x.shape, train_y.shape)\n",
    "print(\"Test shapes: \", test_x.shape, test_y.shape)\n",
    "\n",
    "if valid_dataset is not None:\n",
    "    valid_x, valid_y = valid_dataset.inputs, valid_dataset.outputs.view(-1)\n",
    "    print(\"Valid shapes: \", valid_x.shape, valid_y.shape)\n",
    "\n",
    "del valid_x, valid_y, valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nREDUCE TRAINING DATA\\nnum_instances =  #TODO\\nnum_features = 4\\ntrain_x= torch.split(train_x, grid_size * num_instances)[0]#.reshape(num_instances, grid_size, num_features)\\ntrain_y = torch.split(train_y, grid_size * num_instances)[0]#.reshape(num_instances, grid_size)\\nprint(train_x.shape, train_y.shape)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.data_utils import get_parameters_from\n",
    "from utils.pywake_utils import get_grid_shape\n",
    "x_start, x_end, y_start, y_end, grid_factor, _, _ = get_parameters_from(DATA_FOLDER)\n",
    "grid_shape = get_grid_shape(x_start, x_end, y_start, y_end, grid_factor)\n",
    "grid_size = grid_shape[0] * grid_shape[1]\n",
    "print(grid_size)\n",
    "\n",
    "\"\"\"\n",
    "REDUCE TRAINING DATA\n",
    "\"\"\"\n",
    "num_instances = 1000 #TODO\n",
    "num_features = 4\n",
    "train_x= torch.split(train_x, grid_size * num_instances)[0]#.reshape(num_instances, grid_size, num_features)\n",
    "train_y = torch.split(train_y, grid_size * num_instances)[0]#.reshape(num_instances, grid_size)\n",
    "print(train_x.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "kernel = RBF(length_scale=1.0)\n",
    "gp = GaussianProcessRegressor(kernel=kernel)\n",
    "gp.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "REDUCE TEST DATA\n",
    "\"\"\"\n",
    "num_instances = 100\n",
    "test_x_= torch.split(test_x, grid_size * num_instances)[0]#.reshape(num_instances, grid_size, num_features)\n",
    "test_y_= torch.split(test_y, grid_size * num_instances)[0]#.reshape(num_instances, grid_size)\n",
    "print(test_x.shape, test_y.shape)\n",
    "print(test_x_.shape, test_y_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train results for univariate_skGP_training_factors=ti4-ct4_discr_factors_x2_30_y-2_2_step0.125_TIstep0.01_CTstep0.01 standard multivariate GP\n",
      "r2_score=1.0\n",
      "explained_variance_score=1.0\n",
      "mean_squared_error=5.7518825484673966e-24\n",
      "mean_absolute_error=1.3250620437038523e-12\n",
      "median_absolute_error=1.4278227038200253e-13\n",
      "mean_absolute_percentage_error=1.0000000915781452e-10\n",
      "Prediction time=0.001621548768265971s\n",
      "\n",
      "\n",
      "Test results for univariate_skGP_training_factors=ti4-ct4_discr_factors_x2_30_y-2_2_step0.125_TIstep0.01_CTstep0.01 standard multivariate GP\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# evaluation on trainset\n",
    "save_results = False\n",
    "evaluate_model(gp, data=(train_x, train_y), data_type='train',\n",
    "               model_description=MODEL_DESCRIPTION,\n",
    "               save_results=save_results)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# evalution on testset\n",
    "evaluate_model(gp, data=(test_x, test_y), data_type='test',\n",
    "               model_description=MODEL_DESCRIPTION,\n",
    "               save_results=save_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean(batch_shape=torch.Size([grid_size]))\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.MaternKernel(batch_shape=torch.Size([grid_size])),\n",
    "            batch_shape=torch.Size([grid_size])\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood(batch_shape=torch.Size([grid_size]))\n",
    "model = ExactGPModel(train_x, train_y, likelihood)\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for i in range(EPOCHS):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    try:\n",
    "        print(loss.shape)\n",
    "    except:\n",
    "        pass\n",
    "    loss.backward()\n",
    "    lengthscale = model.covar_module.base_kernel.lengthscale.item()\n",
    "    noise = model.likelihood.noise.item()\n",
    "    print(f\"Iter {i+1}/{EPOCHS} - Loss: {loss.item:.3f}\\tlengthscale: {lengthscale:.3f}\\tnoise: {noise:.3f}\")\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
